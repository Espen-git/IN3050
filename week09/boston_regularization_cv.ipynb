{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization example IN3050 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston.data\n",
    "t = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, t_train, t_val = train_test_split(X, t, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_val.shape, t_train.shape, t_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LinearRegression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr =LinearRegression()\n",
    "lr.fit(X_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(X_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(X_val, t_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr.score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as sk_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_mse(lr.predict(X_val), t_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So far\n",
    "Similar results for train and val. No overfitting. But can we do better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial features\n",
    "We add second order polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly_train = poly.fit_transform(X_train)\n",
    "X_poly_val = poly.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment\n",
    "\n",
    "- 13 original features\n",
    "- 13 squares of original features\n",
    "- 13x12/2 = 78 features of the form $x_ix_j, i\\neq j$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_poly =LinearRegression()\n",
    "lr_poly.fit(X_poly_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_poly.score(X_poly_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_poly.score(X_poly_val, t_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_mse(lr_poly.predict(X_poly_train), t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_mse(lr_poly.predict(X_poly_val), t_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So far\n",
    "Large improvement on *train*. The oposite on *val*. Large difference between *train* and *val*. Overfitting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_poly = Ridge()\n",
    "ridge_poly.fit(X_poly_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ridge?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_mse(ridge_poly.predict(X_poly_val), t_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_mse(ridge_poly.predict(X_poly_train), t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_poly.score(X_poly_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_poly.score(X_poly_val, t_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So far\n",
    "Best score on val so far. Still much better on train. Is the regularization optimal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning regularization\n",
    "An instance of parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in [0, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]:\n",
    "    ridge_poly =Ridge(alpha=a)\n",
    "    ridge_poly.fit(X_poly_train, t_train)\n",
    "    train_score = ridge_poly.score(X_poly_train, t_train)\n",
    "    val_score = ridge_poly.score(X_poly_val, t_val)\n",
    "    train_mse = sk_mse(ridge_poly.predict(X_poly_train), t_train)\n",
    "    val_mse = sk_mse(ridge_poly.predict(X_poly_val), t_val)\n",
    "    print(\"Alpha: {:6}, train_score: {:5.3f}, val_score:{:6.3f}, train_mse: {:7.4f}, val_mse: {:7.4f}\".format(\n",
    "    a, train_score, val_score, train_mse, val_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(10):\n",
    "    a =.5 + 0.1*a\n",
    "    ridge_poly =Ridge(alpha=a)\n",
    "    ridge_poly.fit(X_poly_train, t_train)\n",
    "    train_score = ridge_poly.score(X_poly_train, t_train)\n",
    "    val_score = ridge_poly.score(X_poly_val, t_val)\n",
    "    train_mse = sk_mse(ridge_poly.predict(X_poly_train), t_train)\n",
    "    val_mse = sk_mse(ridge_poly.predict(X_poly_val), t_val)\n",
    "    print(\"Alpha: {:6.1f}, train_score:{:6.3f}, val_score:{:6.3f}, train_mse: {:7.4f}, val_mse: {:7.4f}\".format(\n",
    "    a, train_score, val_score, train_mse, val_mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So far\n",
    "The default regularization factor seems optimal. Best score on val: 0.765."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "Here is still a big gap between train and test. Are there more tools in the drawer? We saw that *Ridge* has a feature for *normalization*. Let us try that one out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in [0, 0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]:\n",
    "    ridge_poly =Ridge(alpha=a, normalize=True)\n",
    "    ridge_poly.fit(X_poly_train, t_train)\n",
    "    train_score = ridge_poly.score(X_poly_train, t_train)\n",
    "    val_score = ridge_poly.score(X_poly_val, t_val)\n",
    "    train_mse = sk_mse(ridge_poly.predict(X_poly_train), t_train)\n",
    "    val_mse = sk_mse(ridge_poly.predict(X_poly_val), t_val)\n",
    "    print(\"Alpha: {:6}, train_score: {:5.3f}, val_score:{:6.3f}, train_mse: {:7.4f}, val_mse: {:7.4f}\".format(\n",
    "    a, train_score, val_score, train_mse, val_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in [0.0006, 0.0007, 0.0008, 0.0009, 0.001, 0.0011, 0.0012, 0.0013, 0.0014]:\n",
    "    ridge_poly =Ridge(alpha=a, normalize=True)\n",
    "    ridge_poly.fit(X_poly_train, t_train)\n",
    "    train_score = ridge_poly.score(X_poly_train, t_train)\n",
    "    val_score = ridge_poly.score(X_poly_val, t_val)\n",
    "    train_mse = sk_mse(ridge_poly.predict(X_poly_train), t_train)\n",
    "    val_mse = sk_mse(ridge_poly.predict(X_poly_val), t_val)\n",
    "    print(\"Alpha: {:6.4f}, train_score: {:5.3f}, val_score:{:6.3f}, train_mse: {:7.4f}, val_mse: {:7.4f}\".format(\n",
    "    a, train_score, val_score, train_mse, val_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So far\n",
    "The best score on *val* is 0.815, achieved with\n",
    "\n",
    "- polynomial features\n",
    "- regularization\n",
    "- $\\alpha=0.001$ \n",
    "\n",
    "We see that neither no regularization ($\\alpha=0$) nor default regularization factor ($\\alpha=1$) improves the results compared to earlier settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs = cross_val_score(LinearRegression(), X_train, t_train, cv=4)\n",
    "print(cvs)\n",
    "print(\"Mean score: {:6.4f}\".format(np.sum(cvs)/len(cvs)))\n",
    "print(\"Standard deviation: {:6.4f}\".format(np.std(cvs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "- Large variation in results.\n",
    "- The conclusions from using one dev-set are less firm\n",
    "- Hopefully, the mean is a better measure than the individual experiments\n",
    "- This set seems too small\n",
    "- (Each traing set is slightly smaller than earlier, 75%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs = cross_val_score(Ridge(), X_train, t_train, cv=4)\n",
    "print(cvs)\n",
    "print(\"Mean score: {:6.4f}\".format(np.sum(cvs)/len(cvs)))\n",
    "print(\"Standard deviation: {:6.4f}\".format(np.std(cvs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs = cross_val_score(Ridge(), X_poly_train, t_train, cv=4)\n",
    "print(cvs)\n",
    "print(\"Mean score: {:6.4f}\".format(np.sum(cvs)/len(cvs)))\n",
    "print(\"Standard deviation: {:6.4f}\".format(np.std(cvs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "- The variation is less than without polynomial features\n",
    "- The mean is better than what we got with one dev-set. (There we were unlucky with the split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# = LinearRegression, no smoothing\n",
    "cvs = cross_val_score(Ridge(alpha=0), X_poly_train, t_train, cv=4)\n",
    "print(cvs)\n",
    "print(\"Mean score: {:6.4f}\".format(np.sum(cvs)/len(cvs)))\n",
    "print(\"Standard deviation: {:6.4f}\".format(np.std(cvs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "- Large variation\n",
    "- The  mean is not impressive\n",
    "- The polynomial features need regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs = cross_val_score(Ridge(normalize=True), X_poly_train, t_train, cv=4)\n",
    "print(cvs)\n",
    "print(\"Mean score: {:6.4f}\".format(np.sum(cvs)/len(cvs)))\n",
    "print(\"Standard deviation: {:6.4f}\".format(np.std(cvs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs = cross_val_score(Ridge(normalize=True, alpha=0.001), X_poly_train, t_train, cv=4)\n",
    "print(cvs)\n",
    "print(\"Mean score: {:6.4f}\".format(np.sum(cvs)/len(cvs)))\n",
    "print(\"Standard deviation: {:6.4f}\".format(np.std(cvs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "- The regularization must be tuned.\n",
    "- The overall results are comparable to polynomial features withou normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
